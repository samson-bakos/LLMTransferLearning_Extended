{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLMs Transfer Learning\n",
    "\n",
    "Notebook by: Samson Bakos\n",
    "\n",
    "Based on the documentation available at: https://huggingface.co"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Text Classification\n",
    "\n",
    "We're going to do this using HF's default objects for simplicity, but you can also do it in Tensorflow/Keras, or PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the [Yelp Reviews Dataset](https://huggingface.co/datasets/yelp_review_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'text': 'My expectations for McDonalds are t rarely high. But for one to still fail so spectacularly...that takes something special!\\\\nThe cashier took my friends\\'s order, then promptly ignored me. I had to force myself in front of a cashier who opened his register to wait on the person BEHIND me. I waited over five minutes for a gigantic order that included precisely one kid\\'s meal. After watching two people who ordered after me be handed their food, I asked where mine was. The manager started yelling at the cashiers for \\\\\"serving off their orders\\\\\" when they didn\\'t have their food. But neither cashier was anywhere near those controls, and the manager was the one serving food to customers and clearing the boards.\\\\nThe manager was rude when giving me my order. She didn\\'t make sure that I had everything ON MY RECEIPT, and never even had the decency to apologize that I felt I was getting poor service.\\\\nI\\'ve eaten at various McDonalds restaurants for over 30 years. I\\'ve worked at more than one location. I expect bad days, bad moods, and the occasional mistake. But I have yet to have a decent experience at this store. It will remain a place I avoid unless someone in my party needs to avoid illness from low blood sugar. Perhaps I should go back to the racially biased service of Steak n Shake instead!'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load dataset \n",
    "dataset = load_dataset(\"yelp_review_full\")\n",
    "\n",
    "# print example from training set\n",
    "dataset[\"train\"][100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each example in this dataset includes a text review from Yelp, along with a star rating (1-5, mapped to labels 0-4)\n",
    "\n",
    "Our task is predict the star rating given the review (5 class classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# use the default preprocessor \n",
    "# important to ensure expected input to our model (i.e. same lemmatization modelling, stopwords, etc)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "   # Map function \n",
    "    # padding and truncation control for variable length sequences\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# apply to all datasets with .map(). Built in function of the HF datasets class\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is slow as heck (unless this is already stored in memory) and that was just preprocessing and loading. \n",
    "\n",
    "Lets take a reduced subset of the data to speed up for demo purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load DistilBert itself\n",
    "\n",
    "This will throw a warning, but its fine.\n",
    "\n",
    "Its basically just telling us this model isn't trained on a specific task yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some setup to do before we start, but there are pretty useful premade functions for us here.\n",
    "\n",
    "There are ALOT of [hyperparameters for training](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments). \n",
    "\n",
    "There are some more important settings like number of epochs, optimizer function (i.e. ADAM, SGD), learning rate, loss function, etc. Reasonable setting for settings are built in as defaults, and alot of the parameters are minor, so we're mostly going to leave this alone. \n",
    "\n",
    "The only thing we'll specify is our output directory, and that we want to see intermediate results every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the model is not evaluated during training (the loss function isn't accuracy, its something like cross-entropy) - we need to be able to pass our Trainer function an evaluation function to have an interpretable way to see what we're doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred # raw outputs, actual labels\n",
    "    predictions = np.argmax(logits, axis=-1) #prediction is the highest output probability\n",
    "    return metric.compute(predictions=predictions, references=labels) # accuracy computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the actual Trainer Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run it!\n",
    "\n",
    "This is slow even with a GPU, smaller BERT model, and smaller dataset - but thats the cost of doing buisness with huge models\n",
    "\n",
    "Bear in mind that with this setup, the model will use your GPU by default if you have one (its using 'mps' on my Apple M1). If you don't have one, this will be even slower.\n",
    "\n",
    "These models are more often used with external cloud computation/ distributed systems where possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0032358169555664062,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 375,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e0ab9eea2e940298aa42c26f7689a2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012156963348388672,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 125,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3644eda0af884733a76f8b33d6d58dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1380902528762817, 'eval_accuracy': 0.505, 'eval_runtime': 67.8238, 'eval_samples_per_second': 14.744, 'eval_steps_per_second': 1.843, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015339851379394531,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 125,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d87eeba06894a5aad08ca7fcfba79bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9756078124046326, 'eval_accuracy': 0.602, 'eval_runtime': 69.2094, 'eval_samples_per_second': 14.449, 'eval_steps_per_second': 1.806, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011960268020629883,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 125,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bdba80647a04e3d8d39dde36172a17f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9829638600349426, 'eval_accuracy': 0.609, 'eval_runtime': 71.9185, 'eval_samples_per_second': 13.905, 'eval_steps_per_second': 1.738, 'epoch': 3.0}\n",
      "{'train_runtime': 836.4285, 'train_samples_per_second': 3.587, 'train_steps_per_second': 0.448, 'train_loss': 0.94194873046875, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=375, training_loss=0.94194873046875, metrics={'train_runtime': 836.4285, 'train_samples_per_second': 3.587, 'train_steps_per_second': 0.448, 'train_loss': 0.94194873046875, 'epoch': 3.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESULTS:\n",
    "\n",
    "Time: ~15 minutes on 2022 Mac M1\n",
    "\n",
    "Epoch 1: 0.493\n",
    "\n",
    "Epoch 2: 0.579\n",
    "\n",
    "Epoch 3: 0.588\n",
    "\n",
    "This hasn't fully converged yet, but it might be starting to slow down.\n",
    "- Could go farther but your computer might be heating up at this point\n",
    "\n",
    "Close only counts in horseshoes and handgrenades - we're not rewarding the model for guessing 2/5 when the actual score is 1/5 - thats just as wrong as 5/5\n",
    "\n",
    "100% accuracy on this task is impossible because not everyone has the same understanding of what each star ratings correspond to - there isn't perfect alignment between the text and the rating\n",
    "\n",
    "We've also shot ourselves in the foot with a really small training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(small_train_dataset['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classical ML for Comparison\n",
    "\n",
    "TF-IDF for representation, Multiclass Naive Bayes for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.438\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = ' '.join([word for word in text.split() if word not in ENGLISH_STOP_WORDS])\n",
    "    return text\n",
    "\n",
    "X_train = [preprocess_text(text) for text in small_train_dataset['text']]\n",
    "y_train = small_train_dataset['label']\n",
    "\n",
    "X_test = [preprocess_text(text) for text in small_eval_dataset['text']]\n",
    "y_test = small_eval_dataset['label']\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're still beating classical ML/NLP by a fair bit! \n",
    "\n",
    "We can imagine that our more complex LLM approach would be able to extract proportionally more value from a larger dataset.\n",
    "\n",
    "Both would (probably) see increased accuracy on the full dataset, but the LLM moreso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Summarizing Text\n",
    "\n",
    "Lets try something we can't do with classical ML!\n",
    "\n",
    "We're going to summarize text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "billsum = load_dataset(\"billsum\", split=\"ca_test\") #legal bill text from California"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'summary', 'title'],\n",
       "    num_rows: 1237\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shrink it cause the full dataset made my computer memory overflow :(\n",
    "billsum = billsum.shuffle(seed=42).select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'summary', 'title'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'The people of the State of California do enact as follows:\\n\\n\\nSECTION 1.\\nSection 3212 of the Labor Code is repealed.\\nSEC. 2.\\nSection 3212 is added to the Labor Code, to read:\\n3212.\\n(a) As used in this act, the term “injury” includes both of the following:\\n(1) With respect to the following members, a hernia, when any part of the hernia develops or manifests itself during a period while the member is in the service of the office, staff, division, department, or unit:\\n(A) Members of a sheriff’s office or the California Highway Patrol, district attorney’s staff of inspectors and investigators, or police or fire departments of cities, counties, cities and counties, districts, or other public or municipal corporations or political subdivisions, whether those members are volunteers, or are partly paid or fully paid.\\n(B) Active firefighting members of the Department of Forestry and Fire Protection whose duties require firefighting or of any county forestry or firefighting department or unit, whether those members are volunteers, or are partly paid or fully paid.\\n(C) Members of the warden service of the Wildlife Branch of the Department of Fish and Wildlife whose principal duties consist of active law enforcement service.\\n(D) Regular salaried county or city and county peace officers.\\n(E) Full-time peace officers, other than those described in subparagraph (A) or (D), as described in Chapter 4.5 (commencing with Section 830) of Title 3 of Part 2 of the Penal Code.\\n(F)\\nUpon the approval of an ordinance or resolution adopted by the governing body of the contracting public agency, or the adoption of language to this effect in a city or county charter, or pursuant to the terms and conditions of employment set forth in a collective bargaining agreement, a\\nA\\ncustody assistant, correctional officer, security officer, or security assistant employed by a public agency, or a peace officer other than a peace officer described in Chapter 4.5 (commencing with Section 830) of Title 3 of Part 2 of the Penal Code.\\n(2) With respect to the following members, pneumonia and heart trouble that develops or manifests itself during a period while the member is in the service of the department:\\n(A) Members of fire departments.\\n(B) Members of county forestry or firefighting departments.\\n(C) Active firefighting members of the Department of Forestry and Fire Protection whose duties require firefighting.\\n(D) Members of the warden service of the Wildlife Branch of the Department of Fish and Wildlife whose principal duties consist of active law enforcement service.\\n(E)\\nUpon the approval of an ordinance or resolution adopted by the governing body of the contracting public agency, or the adoption of language to this effect in a city or county charter, or pursuant to the terms and conditions of employment set forth in a collective bargaining agreement, a\\nA\\ncustody assistant, correctional officer, security officer, or security assistant employed by a public agency, or a peace officer other than a peace officer described in Chapter 4.5 (commencing with Section 830) of Title 3 of Part 2 of the Penal Code.\\n(b) The compensation that is awarded for the hernia, heart trouble, or pneumonia shall include full hospital, surgical, medical treatment, disability indemnity, and death benefits, as provided by the workers’ compensation laws of this state.\\n(c) Hernia, heart trouble, or pneumonia developing or manifesting as described in this section shall be presumed to arise out of and in the course of employment. This presumption is disputable and may be controverted by other evidence, but unless controverted by other evidence, the appeals board is bound to find in accordance with it. The presumption shall be extended to a member following termination of service for a period of three calendar months for each full year of the requisite service, but not to exceed 60 months in any circumstance, commencing with the last date actually worked in the specified capacity.\\n(d) Hernia, heart trouble, or pneumonia developing or manifesting as described in this section shall not be attributed to any disease existing prior to that development or manifestation.\\n(e) This section does not apply to persons whose principal duties are clerical or otherwise do not clearly fall within the scope of active law enforcement, including custody and corrections, firefighting, or emergency first aid response service, such as stenographers, receptionists, and other office workers.\\nSEC. 3.\\nSection 3212.1 of the Labor Code is amended to read:\\n3212.1.\\n(a) This section applies to all of the following:\\n(1) Active firefighting members, whether those members are volunteers, or are partly paid or fully paid, of all of the following fire departments:\\n(A) A fire department of a city, county, city and county, district, or other public or municipal corporation or political subdivision.\\n(B) A fire department of the University of California and the California State University.\\n(C) The Department of Forestry and Fire Protection.\\n(D) A county forestry or firefighting department or unit.\\n(2) Active firefighting members of a fire department that serves a United States Department of Defense installation and who are certified by the Department of Defense as meeting its standards for firefighters.\\n(3) Active firefighting members of a fire department that serves a National Aeronautics and Space Administration installation and who adhere to training standards established in accordance with Article 4 (commencing with Section 13155) of Chapter 1 of Part 2 of Division 12 of the Health and Safety Code.\\n(4) Part-time peace officers, as defined in Section 830.1, subdivision (a) of Section 830.2, and subdivisions (a) and (b) of Section 830.37, of the Penal Code, who are primarily engaged in active law enforcement activities, and full-time peace officers described in Chapter 4.5 (commencing with Section 830) of Title 3 of Part 2 of the Penal Code.\\n(5) (A) Fire and rescue services coordinators who work for the Office of Emergency Services.\\n(B) For purposes of this paragraph, “fire and rescue services coordinators” means coordinators with any of the following job classifications: coordinator, senior coordinator, or chief coordinator.\\n(6)\\nUpon the approval of an ordinance or resolution adopted by the governing body of the contracting public agency, or the adoption of language to this effect in a city or county charter, or pursuant to the terms and conditions of employment set forth in a collective bargaining agreement, a\\nA\\ncustody assistant, correctional officer, security officer, or security assistant employed by a public agency, or a peace officer other than a peace officer described in Chapter 4.5 (commencing with Section 830) of Title 3 of Part 2 of the Penal Code.\\n(b) The term “injury,” as used in this division, includes cancer, including leukemia, that develops or manifests itself during a period in which any member described in subdivision (a) is in the service of the department or unit, if the member demonstrates that he or she was exposed, while in the service of the department or unit, to a known carcinogen as defined by the International Agency for Research on Cancer, or as defined by the director.\\n(c) The compensation that is awarded for cancer shall include full hospital, surgical, medical treatment, disability indemnity, and death benefits, as provided by this division.\\n(d) The cancer so developing or manifesting itself in these cases shall be presumed to arise out of and in the course of the employment. This presumption is disputable and may be controverted by evidence that the primary site of the cancer has been established and that the carcinogen to which the member has demonstrated exposure is not reasonably linked to the disabling cancer. Unless so controverted, the appeals board is bound to find in accordance with the presumption. This presumption shall be extended to a member following termination of service for a period of three calendar months for each full year of the requisite service, but not to exceed 120 months in any circumstance, commencing with the last date actually worked in the specified capacity.\\n(e) The amendments to this section enacted during the 1999 portion of the 1999–2000 Regular Session shall be applied to claims for benefits filed or pending on or after January 1, 1997, including, but not limited to, claims for benefits filed on or after that date that have previously been denied, or that are being appealed following denial.\\n(f) This section shall be known, and may be cited, as the William Dallas Jones Cancer Presumption Act of 2010.\\nSEC. 4.\\nSection 3212.5 of the Labor Code is repealed.\\nSEC. 5.\\nSection 3212.5 is added to the Labor Code, to read:\\n3212.5.\\n(a) The term “injury” as used in this division includes heart trouble and pneumonia that develops or manifests itself during a period while a person described in this subdivision is in the service of the agency, department, or office as described in this subdivision, and the compensation that is awarded for heart trouble or pneumonia as described in this section shall include full hospital, surgical, medical treatment, disability indemnity, and death benefits as provided by the provisions of this division for the following persons when those persons are employed upon a regular, full-time salary:\\n(1) A peace officer described in Chapter 4.5 (commencing with Section 830) of Title 3 of Part 2 of the Penal Code who is employed on a regular, full-time salary.\\n(2) An inspector or investigator in a district attorney’s office of a county who is employed on a regular, full-time salary.\\n(3)\\nUpon the approval of an ordinance or resolution adopted by the governing body of the contracting public agency, or the adoption of language to this effect in a city or county charter, or pursuant to the terms and conditions of employment set forth in a collective bargaining agreement, a\\nA\\ncustody assistant, correctional officer, security officer, or security assistant employed by a public agency, or a peace officer other than a peace officer described in Chapter 4.5 (commencing with Section 830) of Title 3 of Part 2 of the Penal Code.\\n(b) The heart trouble or pneumonia so developing or manifesting itself shall be presumed to arise out of and in the course of the employment; provided, however, that the person shall have served five years or more in that capacity before the presumption shall arise as to the compensability of heart trouble so developing or manifesting itself. This presumption is disputable and may be controverted by other evidence, but, unless so controverted, the appeals board is bound to find in accordance with it. This presumption shall be extended to a person following termination of service for a period of three calendar months for each full year of the requisite service, not to exceed 60 months in any circumstance, commencing with the last date actually worked in the specified capacity.\\n(c) The heart trouble or pneumonia so developing or manifesting itself in these cases shall in no case be attributed to any disease existing prior to its development or manifestation.\\nSEC. 6.\\nSection 3212.6 of the Labor Code is repealed.\\nSEC. 7.\\nSection 3212.6 is added to the Labor Code, to read:\\n3212.6.\\n(a) (1) The term “injury” includes tuberculosis that develops or manifests itself during a period while a person described in this paragraph is in the service of the agency, department, or office as described in this paragraph and the compensation that is awarded for the tuberculosis shall include full hospital, surgical, medical treatment, disability indemnity, and death benefits as provided by the provisions of this division for the following persons:\\n(A) A peace officer described in Chapter 4.5 (commencing with Section 830) of Title 3 of Part 2 of the Penal Code if that person is employed upon a regular, full-time salary.\\n(B) An inspector or investigator in a district attorney’s office of a county who is employed on a regular, full-time salary.\\n(C) A prison or jail guard or correctional officer who is employed by a public agency if that person is employed upon a regular, full-time salary.\\n(D)\\nUpon the approval of an ordinance or resolution adopted by the governing body of the contracting public agency, or the adoption of language to this effect in a city or county charter, or pursuant to the terms and conditions of employment set forth in a collective bargaining agreement, a\\nA\\ncustody assistant, correctional officer, security officer, or security assistant employed by a public agency, or a peace officer other than a peace officer described in Chapter 4.5 (commencing with Section 830) of Title 3 of Part 2 of the Penal Code, if that person is employed upon a regular, full-time salary.\\n(E) A member of a fire department of any city, county, or district, or other public or municipal corporations or political subdivisions, if that person is employed on a regular, fully paid basis.\\n(F) An active firefighting member of the Department of Forestry and Fire Protection whose duties require firefighting and first aid response services, or of a county forestry or firefighting department or unit, if that person is employed on a regular, fully paid basis.\\n(2) The tuberculosis developing or manifesting itself as described in paragraph (1) shall be presumed to arise out of and in the course of the employment. This presumption is disputable and may be controverted by other evidence, but unless so controverted, the appeals board is bound to find in accordance with it. This presumption shall be extended to a person described in paragraph (1) following termination of service for a period of three calendar months for each full year of the requisite service, but not to exceed 60 months in any circumstance, commencing with the last date actually worked in the specified capacity.\\n(b) A public entity may require applicants for employment in firefighting positions who would be entitled to the benefits granted by this section to be tested for infection for tuberculosis.\\n(c) This section does not apply to persons whose principal duties are clerical or otherwise do not clearly fall within the scope of active law enforcement, including custody and corrections, firefighting, or emergency first aid response service, such as stenographers, receptionists, and other office workers.\\nSEC. 8.\\nSection 3212.85 of the Labor Code is repealed.\\nSEC. 9.\\nSection 3212.85 is added to the Labor Code, to read:\\n3212.85.\\n(a) The term “injury,” as used in this division, includes illness or resulting death due to exposure to a biochemical substance that develops or occurs during a period in which a person described in this subdivision is in the service of the agency, department, or unit as described in this subdivision:\\n(1) A part-time peace officer described in Sections 830.1 to 830.5, inclusive, of, or a full-time peace officer described in, Chapter 4.5 (commencing with Section 830) of Title 3 of Part 2 of the Penal Code.\\n(2) A member of a fire department.\\n(3)\\nUpon the approval of an ordinance or resolution adopted by the governing body of the contracting public agency, or the adoption of language to this effect in a city or county charter, or pursuant to the terms and conditions of employment set forth in a collective bargaining agreement, a\\nA\\ncustody assistant, correctional officer, security officer, or security assistant employed by a public agency, or a peace officer other than a peace officer described in Chapter 4.5 (commencing with Section 830) of Title 3 of Part 2 of the Penal Code.\\n(b) The compensation that is awarded for injury pursuant to this section shall include full hospital, surgical, medical treatment, disability indemnity, and death benefits, as provided by this division.\\n(c) The injury that develops or manifests itself in these cases shall be presumed to arise out of, and in the course of, the employment. This presumption is disputable and may be controverted by other evidence. Unless controverted, the appeals board is bound to find in accordance with the presumption. This presumption shall be extended to a person described in subdivision (a) following termination of service for a period of three calendar months for each full year of the requisite service, but not to exceed 60 months in any circumstance, commencing with the last date actually worked in the specified capacity.\\n(d) For purposes of this section, the following definitions apply:\\n(1) “Biochemical substance” means any biological or chemical agent that may be used as a weapon of mass destruction, including, but not limited to, any chemical warfare agent, weaponized biological agent, or nuclear or radiological agent, as these terms are defined in Section 11417 of the Penal Code.\\n(2) “Member of a fire department” includes, but is not limited to, an apprentice, volunteer, partly paid, or fully paid member of any of the following:\\n(A) A fire department of a city, county, city and county, district, or other public or municipal corporation or political subdivision.\\n(B) A fire department of the University of California and the California State University.\\n(C) The Department of Forestry and Fire Protection.\\n(D) A county forestry or firefighting department or unit.\\nSEC. 10.\\nSection 3212.9 of the Labor Code is repealed.\\nSEC. 11.\\nSection 3212.9 is added to the Labor Code, to read:\\n3212.9.\\n(a) The term “injury” includes meningitis that develops or manifests itself when one of the following persons is in the service of the agency, department, or unit as described in this subdivision and the compensation that is awarded for meningitis shall include full hospital, surgical, medical treatment, disability indemnity, and death benefits as provided by this division:\\n(1) A peace officer described in Chapter 4.5 (commencing with Section 830) of Title 3 of Part 2\\nof the\\nPenal Code who is employed on a regular, full-time salary.\\n(2) An inspector or investigator in a district attorney’s office of a county whose principal duties consist of active law enforcement service and who is employed on a regular, full-time salary.\\n(3) A member of a fire department of any city, county, or district, or other public or municipal corporation or political subdivision, or a county forestry or firefighting department or unit, who is employed on a regular, full-time salary.\\n(4)\\nUpon the approval of an ordinance or resolution adopted by the governing body of the contracting public agency, or the adoption of language to this effect in a city or county charter, or pursuant to the terms and conditions of employment set forth in a collective bargaining agreement, a\\nA\\ncustody assistant, correctional officer, security officer, or security assistant employed by a public agency, or a peace officer other than a peace officer described in Chapter 4.5 (commencing with Section 830) of Title 3 of Part 2 of the Penal Code who is employed on a regular, full-time salary.\\n(b) For purposes of this section, meningitis shall be presumed to arise out of, and in the course of, the employment. This presumption is disputable and may be controverted by other evidence, but unless so controverted, the appeals board is bound to find in accordance with it. This presumption shall be extended to a person following termination of service for a period of three calendar months for each full year of the requisite service, but not to exceed 60 months in any circumstance, commencing with the last date actually worked in the specified capacity.\\n(c) This section does not apply to persons whose principal duties are clerical or otherwise do not clearly fall within the scope of active law enforcement, including custody and corrections, or firefighting, such as stenographers, receptionists, and other office workers.',\n",
       " 'summary': 'Existing law establishes a workers’ compensation system to compensate an employee for injuries arising out of, and in the course of, his or her employment. Existing law designates illnesses and conditions that constitute a compensable injury for various employees, such as California Highway Patrol members, firefighters, and certain peace officers. These injuries include, but are not limited to, hernia, pneumonia, heart trouble, cancer, meningitis, and exposure to a biochemical substance when the illness or condition develops or manifests itself during a period when the officer or employee is in service of his or her employer, as specified.\\nThis bill would expand the coverage of the above provisions relating to compensable injury, to include other, full-time peace officers described pursuant to specified provisions of law. The bill would also expand the coverage of these provisions to\\ninclude, upon the approval of an ordinance or resolution adopted by the governing body of the contracting public agency, or the adoption of language to this effect in a city or county charter, or pursuant to the terms and conditions of employment set forth in a collective bargaining agreement,\\ninclude\\na custody assistant, correctional officer, security officer, or security assistant employed by a public agency, or a peace officer other than a peace officer to whom these provisions already apply. The bill would also make technical and clarifying changes.',\n",
       " 'title': 'An act to amend Section 3212.1 of, and to repeal and add Sections 3212, 3212.5, 3212.6, 3212.85, and 3212.9 of, the Labor Code, relating to workers’ compensation.'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billsum = billsum.train_test_split(test_size=0.2)\n",
    "\n",
    "billsum['train'][0]\n",
    "\n",
    "# We have a long version - our input\n",
    "# And a summary - our desired output\n",
    "\n",
    "# Training on the task of transforming a 'text' into its corresponding 'summary', we'll create a legal explanation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"google-t5/t5-small\" # We need an encoder-decoder model since we're going text-text\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint) # Use the right tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"summarize: \" # This is a multipurpose model - we need to attach a task to tell it what we want\n",
    "# Just like how you prompt chat GPT with specific questions\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"text\"]] # add summarize to texts\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True) # tokenize inputs\n",
    "    labels = tokenizer(text_target=examples[\"summary\"], max_length=128, truncation=True) # tokenize outputs\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"] # match up the text and summary. Specific to this application\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0027887821197509766,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 80,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef9156cad3184c62b1c8c8ffd299a99b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003926753997802734,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 20,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20e6498850ce472fb5b0e1f4bae296e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_billsum = billsum.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint) # batch examples\n",
    "# Better for computation and memory\n",
    "# Also makes it easier/less disruptive to make all sequences in a batch the same length, rather than the whole dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = evaluate.load(\"rouge\") # metric\n",
    "# specially designed metric for summarization tasks: https://huggingface.co/spaces/evaluate-metric/rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the documentation, don't worry about syntax here\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint) # load t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training args:\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"billsum_model\", \n",
    "    evaluation_strategy=\"epoch\", \n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    weight_decay=0.01, # regularization in optimizer\n",
    "    save_total_limit=3, # maximum number of versions to have saved\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate= True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build trainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_billsum[\"train\"],\n",
    "    eval_dataset=tokenized_billsum[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0' # don't try this at home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003426074981689453,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 60,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9b1963f07474254bbda1a320ae1b46e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/opt/miniconda3/lib/python3.10/site-packages/transformers/generation/utils.py:1355: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014121294021606445,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 5,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5198161526aa4499b576f81bfac30149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.7612648010253906, 'eval_rouge1': 0.1369, 'eval_rouge2': 0.0436, 'eval_rougeL': 0.1222, 'eval_rougeLsum': 0.1229, 'eval_gen_len': 19.0, 'eval_runtime': 10.5324, 'eval_samples_per_second': 1.899, 'eval_steps_per_second': 0.475, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012366056442260742,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 5,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92e2f3def2964b30a9f636efe3b8fdb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.336975574493408, 'eval_rouge1': 0.1355, 'eval_rouge2': 0.044, 'eval_rougeL': 0.1219, 'eval_rougeLsum': 0.1223, 'eval_gen_len': 19.0, 'eval_runtime': 7.739, 'eval_samples_per_second': 2.584, 'eval_steps_per_second': 0.646, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004637956619262695,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 5,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc015717f5054296982a286c4cbfedb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.2518959045410156, 'eval_rouge1': 0.129, 'eval_rouge2': 0.0382, 'eval_rougeL': 0.1123, 'eval_rougeLsum': 0.1127, 'eval_gen_len': 19.0, 'eval_runtime': 8.1974, 'eval_samples_per_second': 2.44, 'eval_steps_per_second': 0.61, 'epoch': 3.0}\n",
      "{'train_runtime': 301.3856, 'train_samples_per_second': 0.796, 'train_steps_per_second': 0.199, 'train_loss': 3.7708613077799478, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=60, training_loss=3.7708613077799478, metrics={'train_runtime': 301.3856, 'train_samples_per_second': 0.796, 'train_steps_per_second': 0.199, 'train_loss': 3.7708613077799478, 'epoch': 3.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('billsum_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"summarize: The Inflation Reduction Act lowers prescription drug costs, health care costs, and energy costs. It's the most aggressive action on tackling the climate crisis in American history, which will lift up American workers and create good-paying, union jobs across the country. It'll lower the deficit and ask the ultra-wealthy and corporations to pay their fair share. And no one making under $400,000 per year will pay a penny more in taxes.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: the Inflation Reduction Act lowers prescription drug costs, health care costs, and energy costs. it's the most aggressive action on tackling the climate crisis in American history. no one making under $400,000 per year will pay a penny more in taxes.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"billsum_model\", local_files_only=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"billsum_model\", local_files_only=True)\n",
    "\n",
    "# Tokenize the input text\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "\n",
    "# Generate summary\n",
    "summary_ids = model.generate(inputs[\"input_ids\"], num_beams=4, min_length=None, max_length=60, early_stopping=True)\n",
    "\n",
    "# Decode the summary\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Print the summary\n",
    "print(\"Summary:\", summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty similar but with a bit less fluff. Note that this was a VERY minimal training to allow it to work locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
